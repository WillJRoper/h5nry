# H5nry

An AI assistant for investigating HDF5 files in your terminal.

H5nry (pronounced "Henry") is a Textual TUI + CLI tool that lets you chat with a Large Language Model about the contents of HDF5 files. The LLM can explore file structure, inspect metadata, compute statistics, generate plots, and optionally run Python snippetsâ€”all while respecting configurable memory limits.

## Features

- ðŸ¤– **AI-Powered Exploration**: Chat naturally with your HDF5 files using OpenAI, Anthropic, or Google Gemini
- ðŸ“Š **Smart Data Handling**: Automatically chunks large datasets to respect memory limits
- ðŸŽ¨ **Interactive TUI**: Full-screen terminal interface built with Textual
- ðŸ”’ **Safety Levels**: Choose between tools-only or tools-plus-python execution modes
- ðŸ“ˆ **Built-in Analytics**: Compute statistics, generate histograms, and create plots
- âš¡ **Async Design**: Responsive UI that doesn't block during LLM calls

## Installation

```bash
# Clone the repository
git clone https://github.com/WillJRoper/h5nry.git
cd h5nry

# Install in development mode
pip install -e .

# Install pre-commit hooks (for contributors)
pre-commit install
```

## Quick Start

### 1. Login to an AI Provider

Before using H5nry, you need to configure an API key for your chosen LLM provider:

```bash
# For OpenAI
h5nry login openai

# For Anthropic
h5nry login anthropic

# For Google Gemini
h5nry login gemini
```

Alternatively, set environment variables:
- `OPENAI_API_KEY`
- `ANTHROPIC_API_KEY`
- `GEMINI_API_KEY`

### 2. Interactive Mode (TUI)

Launch the full-screen chat interface:

```bash
h5nry path/to/your/file.h5
```

Inside the TUI:
- Type your questions and press Enter
- Use `/history` to view recent code snippets
- Use `/show N` to display a specific code snippet
- Press Ctrl+C to exit

### 3. One-Shot Mode

Get a quick answer without entering the TUI:

```bash
h5nry ask path/to/file.h5 "What is the mean of /gas/temperature?"
h5nry ask data.h5 "Give me a high-level summary of this file"
```

## Configuration

H5nry stores configuration in `~/.h5nry/config.yaml`. You can customize:

### Provider Settings

```yaml
# Which LLM provider to use
provider: openai  # options: openai, anthropic, gemini

# Model name
model: gpt-4-turbo-preview

# Temperature (0.0 - 1.0)
temperature: 0.1

# Max tokens (optional)
max_tokens: null

# Enable streaming responses
stream: true
```

### Safety Settings

```yaml
# Safety level determines what tools are available
safety_level: tools_only  # options: tools_only, tools_plus_python
```

- **`tools_only`**: The LLM can only use curated HDF5 inspection, statistics, and plotting tools. No arbitrary code execution.
- **`tools_plus_python`**: In addition to curated tools, the LLM can execute Python snippets in a restricted environment.

### Memory Limits

```yaml
# Maximum data to load into memory at once (in GB)
max_data_gb: 0.5
```

All dataset-reading operations automatically chunk data to respect this limit. This prevents out-of-memory errors when working with large HDF5 files.

### Code History

```yaml
# Maximum number of executed code snippets to keep in memory
recent_code_limit: 20
```

## How It Works

### HDF5 Pre-Parsing

When you open a file, H5nry:
1. Walks the entire HDF5 tree structure
2. Builds a lightweight in-memory representation
3. Reads all attribute names and types
4. Automatically loads "description" attributes (case-insensitive)
5. Provides this context to the LLM in the system prompt

### Memory-Safe Operations

All data-reading operations (statistics, histograms, plotting) respect the `max_data_gb` limit by:
- Computing dataset sizes before reading
- Automatically chunking large datasets
- Aggregating results in streaming fashion
- Raising clear errors if an operation can't be performed within the limit

### Available Tools

The LLM has access to these tool families:

- **HDF5 Tree Tools**: List groups, inspect datasets, read attributes
- **Statistics Tools**: Compute min/max/mean/std, create histograms
- **Plotting Tools**: Generate histogram plots saved to disk
- **Python Execution** (if `safety_level: tools_plus_python`): Run small Python snippets with `numpy` and `h5py` pre-imported

## Development

### Running Tests

```bash
pytest
```

### Code Quality

This project uses:
- **ruff** for linting and formatting
- **pre-commit** for automated checks
- **pytest** for testing

```bash
# Run ruff manually
ruff check .
ruff format .

# Run pre-commit on all files
pre-commit run --all-files
```

### Project Structure

```
h5nry/
â”œâ”€â”€ src/h5nry/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py              # Main orchestrator
â”‚   â”œâ”€â”€ cli.py              # CLI entrypoint
â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â”œâ”€â”€ session.py          # LLM + tools orchestration
â”‚   â”œâ”€â”€ tui.py              # Textual TUI
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ default_config.yaml
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py         # Abstract LLM client
â”‚   â”‚   â”œâ”€â”€ openai_client.py
â”‚   â”‚   â”œâ”€â”€ anthropic_client.py
â”‚   â”‚   â””â”€â”€ gemini_client.py
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ hdf5_tree.py    # HDF5 inspection tools
â”‚       â”œâ”€â”€ stats.py        # Statistics tools
â”‚       â”œâ”€â”€ plotting.py     # Plotting tools
â”‚       â””â”€â”€ python_exec.py  # Python execution tool
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_hdf5_tree.py
â”‚   â””â”€â”€ test_stats.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

## License

MIT License - see [LICENSE](LICENSE) for details.

## Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes with tests
4. Run `pre-commit run --all-files`
5. Submit a pull request

## Acknowledgments

H5nry is designed for HPC developers and scientists working with large HDF5 datasets. Inspired by modern AI coding assistants and built with [Textual](https://textual.textualize.io/).
